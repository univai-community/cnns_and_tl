{"cells":[{"cell_type":"markdown","metadata":{},"source":["# The multi-layer perceptron with Regularization\n","\n","We use a special technique, called **Dropout**. Here we randomly sever connections to and from some fraction of nodes in \"previous\" layer in every epoch.\n","\n","It prevents overfitting by not allowing specific nodes to specialize to say, for example \"cat eye detection\" at the expense of other things. By severing, other neurons are forced to step in.\n","\n","It is done only during training, at prediction time the connections are restored with the final weights that we computed\n","\n","![](images/Figure-20-008.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9523,"status":"ok","timestamp":1674094316305,"user":{"displayName":"Rahul Dave","userId":"03742901065991133251"},"user_tz":300},"id":"QrJS1RP2yxBL"},"outputs":[],"source":["from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Dropout\n","from keras.utils import to_categorical\n","from keras.utils import np_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":152,"status":"ok","timestamp":1674094316453,"user":{"displayName":"Rahul Dave","userId":"03742901065991133251"},"user_tz":300},"id":"TTGdO_c5y4VY"},"outputs":[],"source":["class Config:\n","  pass\n","config = Config()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3753,"status":"ok","timestamp":1674094323748,"user":{"displayName":"Rahul Dave","userId":"03742901065991133251"},"user_tz":300},"id":"vnixVpF4y9vb","outputId":"7cb01ab4-802d-4b13-8bf7-a90d79f90cf3"},"outputs":[],"source":["config.optimizer = \"adam\"\n","config.epochs = 10\n","config.hidden_nodes = 100\n","\n","# load data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","img_width = X_train.shape[1]\n","img_height = X_train.shape[2]\n","\n","X_train = X_train.astype('float32')\n","X_train /= 255.\n","X_test = X_test.astype('float32')\n","X_test /= 255.\n","\n","# one hot encode outputs\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)\n","labels = range(10)\n","\n","num_classes = y_train.shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":123,"status":"ok","timestamp":1674094888079,"user":{"displayName":"Rahul Dave","userId":"03742901065991133251"},"user_tz":300},"id":"ojOlQ7pOzMye"},"outputs":[],"source":["config.dropout = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1674094889251,"user":{"displayName":"Rahul Dave","userId":"03742901065991133251"},"user_tz":300},"id":"qSWdH6dPzBh_","outputId":"2b6b66ec-9ad2-486b-f71b-079c0841add3"},"outputs":[],"source":["# create model\n","model=Sequential()\n","model.add(Flatten(input_shape=(img_width,img_height)))\n","model.add(Dropout(config.dropout))\n","model.add(Dense(config.hidden_nodes, activation='relu'))\n","model.add(Dropout(config.dropout))\n","model.add(Dense(num_classes, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer=config.optimizer,\n","                    metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82603,"status":"ok","timestamp":1674094972720,"user":{"displayName":"Rahul Dave","userId":"03742901065991133251"},"user_tz":300},"id":"EFTa7kQZzSCs","outputId":"18ed59fe-097a-44e9-f372-92d0249dd554"},"outputs":[],"source":["history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","          epochs=config.epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1674094973034,"user":{"displayName":"Rahul Dave","userId":"03742901065991133251"},"user_tz":300},"id":"B2rb8VNqza7U","outputId":"02401ceb-995e-4ea0-b3a8-9e626aa4986b"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1674094973327,"user":{"displayName":"Rahul Dave","userId":"03742901065991133251"},"user_tz":300},"id":"KM5-IzI3zeli","outputId":"a95e0ee8-08a2-4c2c-892b-1a792cbba0a1"},"outputs":[],"source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])"]},{"cell_type":"markdown","metadata":{},"source":["Now we do much better.\n","\n","## TECHNIQUE\n","\n","1. normalize data, and initialize coefficients\n","2. increase complexity until you overfit: layers, Dense layers\n","4. increase rregularization until we dont overfit any more. Do this via dropout and weight-decay (Ridge regularization, more later)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOZWfr18s9OuvwLiwCLF0XP","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.11.1 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.1"},"vscode":{"interpreter":{"hash":"5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"}}},"nbformat":4,"nbformat_minor":0}
